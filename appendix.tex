\section{Appendix}


Include extra information in the appendix. This section will often be part of the supplemental material. Please see the call on the NeurIPS website for links to additional guides on dataset publication.

\begin{enumerate}

% \item Submission introducing new datasets must include the following in the supplementary materials:
% \begin{enumerate}
  % \item Dataset documentation and intended uses. Recommended documentation frameworks include datasheets for datasets, dataset nutrition labels, data statements for NLP, and accountability frameworks.
  % \item URL to website/platform where the dataset/benchmark can be viewed and downloaded by the reviewers.
  % \item Author statement that they bear all responsibility in case of violation of rights, etc., and confirmation of the data license.
  % \item Hosting, licensing, and maintenance plan. The choice of hosting platform is yours, as long as you ensure access to the data (possibly through a curated interface) and will provide the necessary maintenance.
% \end{enumerate}

\item To ensure accessibility, the supplementary materials for datasets must include the following:
\begin{enumerate}
  % \item Links to access the dataset and its metadata. This can be hidden upon submission if the dataset is not yet publicly available but must be added in the camera-ready version. In select cases, e.g when the data can only be released at a later date, this can be added afterward. Simulation environments should link to (open source) code repositories.
  % \item The dataset itself should ideally use an open and widely used data format. Provide a detailed explanation on how the dataset can be read. For simulation environments, use existing frameworks or explain how they can be used.
  % \item Long-term preservation: It must be clear that the dataset will be available for a long time, either by uploading to a data repository or by explaining how the authors themselves will ensure this.
  % \item Explicit license: Authors must choose a license, ideally a CC license for datasets, or an open source license for code (e.g. RL environments).
  % \item Add structured metadata to a dataset's meta-data page using Web standards (like schema.org and DCAT): This allows it to be discovered and organized by anyone. If you use an existing data repository, this is often done automatically.
  \item Highly recommended: a persistent dereferenceable identifier (e.g. a DOI minted by a data repository or a prefix on identifiers.org) for datasets, or a code repository (e.g. GitHub, GitLab,...) for code. If this is not possible or useful, please explain why.
\end{enumerate}

\item For benchmarks, the supplementary materials must ensure that all results are easily reproducible. Where possible, use a reproducibility framework such as the ML reproducibility checklist, or otherwise guarantee that all results can be easily reproduced, i.e. all necessary datasets, code, and evaluation procedures must be accessible and documented.

\item For papers introducing best practices in creating or curating datasets and benchmarks, the above supplementary materials are not required.
\end{enumerate}

Please refer to \url{https://github.com/EpistasisLab/srbench/} for the most up-to-date guide to running the benchmark study. 

\subsection{Running the Benchmark}

\subsection{Dataset Information}
All datasets, including metadata, are available from \href{https://epistasislab.github.io/pmlb/}{PMLB}. 
Each dataset is stored using Git Large File Storage and PMLB is planned for long-term maintenance.
PMLB is available under an MIT license, and is described in detail in~\citet{romanoPMLBV1Open2021}. 
The authors bear all responsibility in case of violation of rights.

\paragraph{Ethical Considerations and Intended Uses}
PMLB is intended to be used as a framework for benchmarking ML and SR algorithms and as a resource for investigating the structure of datasets. 
This paper does not contribute new datasets, but rather collates and standardizes datasets that were already publicly available.
In that regard, we do not foresee it as creating additional ethical issues around their use. 
However, it is worth noting that PMLB contains well-known, real-world datasets from UCI and OpenML for which ethical considerations are important, such as the \href{https://github.com/EpistasisLab/pmlb/blob/master/datasets/1089_USCrime/metadata.yaml}{USCrime} dataset. 
Whereas we would view the risk of harm arising specifically from this dataset to be low (the data is from 1960), it is examplary of a task for which algorithmic decision making could exacerbate existing biases in the criminal justice system.  
As such it is used as a benchmark in a number of papers in the ML fairness literature (e.g.~\cite{kearnsPreventingFairnessGerrymandering2018}). 


\paragraph{Feynman datasets}
The Feynman benchmarks were sourced from the \href{https://space.mit.edu/home/tegmark/aifeynman.html}{Feynman Symbolic Regression Database}. 
We standardized the Feynman and Bonus equations to PMLB format and included metadata detailing the model form and the units for each variable. 
We used the version of the equations that were not simplified by dimensional analysis. 
\citet{udrescuAIFeynmanPhysicsInspired2020} describe each dataset as containing $10^5$ rows, but each actually contains $10^6$. 
Given this discrepancy and after noting that subsampling did not significantly change the correlation structure of any of the problems, each dataset was downsampled from 1 million samples to 100,000 to lower the computational burden.
We also observed that Eqn. II.11.17 was missing from the database. 
Finally, we excluded three datasets from our analysis that contained $\arcsin$ and $\arccos$ functions, as these were not implemented in the majority of SR algorithms we tested.

\paragraph{Strogatz datasets}
The Strogatz datasets were sourced from the \href{https://github.com/lacava/ode-strogatz}{ODE-Strogatz repository}.
Each dataset is one state of a 2-state system of first-order, ordinary differential equations (ODEs). 
The goal of each problem is to predict rate of change of the state given the current two states on which it depends. 
The problems are adapted from~\cite{strogatzNonlinearDynamicsChaos2014} and represent natural processes that exhibit chaos and non-linear dynamics.  
In order to simulate their behavior, initial conditions were chosen within stable basins of attraction.
Each system was simulated using Simulink, and the code is available in the repository.

\subsection{Contributing a Method}
A living version of the method contribution instructions are described in the \href{https://github.com/EpistasisLab/srbench/blob/master/CONTRIBUTING.md}{Contribution Guide}.
To illustrate the simplicity of contributing a method, Figure~\ref{fig:ex_code} shows the script submitted for Bayesian Symbolic Regression~\cite{jinBayesianSymbolicRegression2020}. 
In addition to the code snippet, authors may either add their code package to the conda/pip environment, or provide an install script.
When a pull request is issued by a contributor, new methods and installs are automatically tested on a minimal version of the benchmark.  

\begin{figure}
	\input{contribution_example}
    \caption{
        An example code contribution, defining the estimator, its hyperparameters, and functions to return the complexity and symbolic model.
    }\label{fig:ex_code} 
\end{figure}

\subsection{Additional Experiment Details}

%% LPC


%% dealing with fails

%% Hyperparameters of each method
\begin{table}
    \footnotesize
    \centering

    \caption{
        ML methods and the hyperparameter spaces used in tuning.
    }
    \rowcolors{2}{gray!25}{white}
    \input{tables/ml_methods_hp_table}
    
\end{table}

\begin{table}
    \footnotesize
    \centering
    \caption{
        Part 1: SR methods and the hyperparameter spaces used in tuning on the black-box regression problems.
    }
    \input{tables/sr_methods_hp_table1}
\end{table}

\begin{table}
    \scriptsize

    \centering

    \caption{
        Part 2: SR methods and the hyperparameter spaces used in tuning on the black-box regression problems.
    }
    \input{tables/sr_methods_hp_table2}
\end{table}
